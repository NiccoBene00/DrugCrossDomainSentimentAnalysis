# Cross Domain Sentiment Analysis on Drugs Reviews - UNIFI
## Author: Niccolò Benedetto 
## Supervisor: Paolo Frasconi

> [!IMPORTANT]
> Repository Contents:
>  - **Cross_Domain_SentimentAnlysis.ipynb**, a Jupyter Notebook with the project code implemented using [Google Colab](https://colab.google/).
>  - **CD_SentimentAnalysis.pdf**, a PDF file generated with [LaTeX](https://www.latex-project.org/) containing the project documentation.

**Project Assignment**:

*In this project, available implementations of the Perceptron algorithm (e.g., [scikit-learn](https://scikit-learn.org/stable/) in Python or [Weka](https://ml.cms.waikato.ac.nz/weka/) in Java) are applied to the problem of sentiment analysis on drug reviews, as described in [Gräßer et al. 2018](https://dl.acm.org/doi/10.1145/3194658.3194677), attempting to reproduce results similar to those reported in Table 3 of the paper (cross-domain case). Numerical results may differ since the authors use a different classifier. The dataset is available on the [UCI repository](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29). It is acceptable to use a subset of the data and/or simplify the lexical attributes (e.g., avoiding trigrams) if the available computing resources are insufficient.*

> [!NOTE]
> **Useful Information**
> 
> The implementation of the code required for the project follows these steps:
>  1. **Data Preparation of the Dataset:**
>     Pre-processing of the text (removal of alphanumeric characters, conversion to lowercase, tokenization, removal of stop-words) of the reviews using the [NLTK](https://www.nltk.org/#natural-language-toolkit) library and sentiment evaluation using the [VADER](https://pypi.org/project/vaderSentiment/) tool. This evaluation will provide a quantifier (a real number) that is used to define a new column in the dataset, representing a new rating value, which will be used as the model label. Specifically, if the quantifier falls within the range [-1; -0.3], then the rating value is 0 (negative sentiment), if it falls in (-0.3; 0.3), then the rating corresponds to 1 (neutral sentiment), while if it falls within the range [0.3; 1], the rating is 2 (positive sentiment).
> 
>     **Note:** The chosen range for defining the new rating value is considered consistent with the meaning of the compound values generated by the VADER tool (see [about the scoring of VADER analysis](https://github.com/cjhutto/vaderSentiment)). Different interval choices may produce different results after model training.
> 
>     [1] @Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.
>  2. **Model Building:**
>     The model uses the review texts as training data, thus associating each text with its corresponding rating value (rating_model) calculated during the data preparation phase.
>
>     **Note:** The model is also trained on the raw review texts (i.e., without any text pre-processing). The comparative analysis of the results (obtained for "raw" and "clean" reviews) will provide some insights into the usefulness of using the NLTK library.
>  3. **Training and Testing the Model:**
>     The extraction of lexical features from the training data is performed using the TfidfVectorizer class from the scikit-learn module. This produces a new matrix representation where rows correspond to texts and columns correspond to values proportional to the features, taking into account both the frequency of words in the document and the inverse frequency in the training corpus (see [about TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#) for more info). The model is then trained using the Perceptron predictive algorithm, which is provided as input with the extracted lexical features and their corresponding labels. The cross-domain analysis then requires iteratively using Perceptron for training and testing the model on review texts belonging to portions of the overall dataset, obtained by considering all possible combinations by crossing pairs of domains (see the project documentation for further clarifications).
>
>     **Note:** During the lexical feature extraction phase, the TfidfVectorizer instance considers the words in the review texts as the analysis units; specifically, it evaluates unigrams (single words) and bigrams (adjacent word pairs), differently from the work described in [Gräßer et al. 2018](https://dl.acm.org/doi/10.1145/3194658.3194677), which also considers trigrams.
>  4. **Producing the Results:**
>     The Perceptron generates a quantifier, defined as the prediction accuracy, obtained by comparing the array of true labels from the test data with the array of predictions made. Accuracy is calculated as the ratio of correct predictions to the total number of predictions generated. The associated quantifier will be a number between 0 (no correct predictions) and 1 (all predictions are correct).

